{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dbf10b-a848-4b03-ad8d-379b9316ebe8",
   "metadata": {},
   "source": [
    "# Lab Objective :  Connect with Google GEN AI (google plam) and ask a question unsing langchain\n",
    "\n",
    "<b>References </b> <br>\n",
    "https://python.langchain.com/docs/integrations/platforms/google<br>\n",
    "\n",
    "<b>Prerequisite </b> <br>\n",
    "Makesure to setup API key in your enviroments i.e. <br>\n",
    "%env GOOGLE_API_KEY=<><br>\n",
    "Must install #pip install langchain-google-genai<br>\n",
    "\n",
    "<b> Troubleshooting - 1: IProgress not found.... </b>\n",
    "<p>\n",
    "\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html.   from .autonotebook import tqdm as notebook_tqdm <br>\n",
    "\n",
    "<b> Resolution</b>: Install pip install ipywidgets widgetsnbextension pandas-profiling  <br>\n",
    "</p>\n",
    "\n",
    "Refer to requirment,txt<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f76c61-4079-4282-bbc0-b23955ec6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY=os.environ['GOOGLE_API_KEY'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43352de-9b8c-4705-a163-89ab7d3974eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae745ea-0392-4e23-9476-28b577811bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'November in Washington, D.C. is typically cold, with average temperatures ranging from 36°F to 54°F.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How Cold november is in DC, answer in one line\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2002bc3-675f-4501-bf19-12ed6f29ed3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PaLM is the latest, as of my knowledge cutoff in September 2021. [Document Link](https://ai.googleblog.com/2020/05/palm-scaling-language-models-up-to.html)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"In one line , which one is letest  PaLM or Gemini llm and show document link\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abb254f-4895-41d3-b41d-60527dafcb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PaLM is the latest.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"In one line , which one is letest  PaLM or Gemini llm\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1d33d3-7f47-47ec-b745-a47166f18cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='PaLM is the latest.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"In one line , which one is letest  PaLM or Gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84fefb1-ad12-48af-9fa5-b7d95d1ab0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Gemini** is the latest large language model (LLM) developed by Google, as of my knowledge cutoff in September 2021. \\n\\nHowever, it's important to note that Google has continued to develop and release new LLMs since then, and there may have been subsequent releases after Gemini. To obtain the most up-to-date information on Google's latest LLM, I recommend checking reputable tech news sources or Google's official website.\\n\\n**PaLM (Pathways Language Model)** is another LLM developed by Google, but it is not the latest one. \\n\\nAs of my knowledge cutoff, PaLM was released in 2022 and had 540 billion parameters, making it one of the largest LLMs at the time. However, Gemini was released after PaLM and has 1.6 trillion parameters, making it significantly larger and more powerful.\\n\\nTherefore, based on the information available to me, **Gemini is the latest LLM** developed by Google. However, it's worth checking Google's official sources for the most current information on their LLMs.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"which llm is letest  PaLM or Gemini\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "986e9731-41ce-4cf9-8aaa-9201350cbda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PaLM, the language model so grand,\\n\\nGemini's power, in AI's own hand.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"PaLM or Gemini, answer in two lines\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c17c470c-5515-4c14-8150-880828204aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PaLM (Pathways Language Model) and Gemini are both large language models developed by Google. However, there are some key differences between the two models.\\n\\n**Size:**\\n\\n* PaLM has 540 billion parameters, while Gemini has 280 billion parameters. This makes PaLM the larger and more powerful model.\\n\\n**Architecture:**\\n\\n* PaLM is based on the Transformer architecture, while Gemini is based on a novel architecture called the Switch Transformer. The Switch Transformer is designed to be more efficient and scalable than the Transformer architecture.\\n\\n**Training:**\\n\\n* PaLM was trained on a massive dataset of text and code, while Gemini was trained on a smaller dataset of text. This gives PaLM an advantage in terms of knowledge and understanding.\\n\\n**Performance:**\\n\\n* PaLM has been shown to outperform Gemini on a variety of language tasks, including text summarization, question answering, and code generation.\\n\\n**Availability:**\\n\\n* PaLM is not currently available to the public, while Gemini is available to researchers and developers through Google's Cloud TPUs platform.\\n\\nOverall, PaLM is a larger, more powerful, and more versatile language model than Gemini. However, Gemini is still a very capable model, and it has the potential to be used for a wide variety of applications.\\n\\nHere is a table summarizing the key differences between PaLM and Gemini:\\n\\n| Feature | PaLM | Gemini |\\n|---|---|---|\\n| Size | 540 billion parameters | 280 billion parameters |\\n| Architecture | Transformer | Switch Transformer |\\n| Training | Trained on a massive dataset of text and code | Trained on a smaller dataset of text |\\n| Performance | Outperforms Gemini on a variety of language tasks | Capable model with potential for a wide range of applications |\\n| Availability | Not currently available to the public | Available to researchers and developers through Google's Cloud TPUs platform |\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"PaLM vs Gemini\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce06b467-5b2a-4eee-a68d-05908cf10ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The choice between PaLM and Gemini depends on your specific needs and requirements. Here's a comparison of both models to help you make an informed decision:\\n\\n1. **Model Size and Architecture**:\\n   - PaLM: PaLM is a much larger model than Gemini, with 540 billion parameters compared to Gemini's 280 billion parameters. This means that PaLM has a greater capacity to learn and retain information.\\n   - Gemini: Gemini's architecture is based on Google's Switch Transformer, which is specifically designed for efficient training and inference. It allows Gemini to achieve state-of-the-art performance with fewer parameters.\\n\\n2. **Training Data**:\\n   - PaLM: PaLM was trained on a massive dataset of text, code, and images, which gives it a wide range of knowledge and the ability to generate text, write code, and answer complex questions.\\n   - Gemini: Gemini was trained on a smaller dataset focused on natural language processing tasks, such as question answering, summarization, and text generation.\\n\\n3. **Generalization and Adaptability**:\\n   - PaLM: PaLM's large size and diverse training data allow it to generalize well to new tasks and domains. It can adapt to various prompts and generate creative and informative responses.\\n   - Gemini: While Gemini is not as versatile as PaLM due to its smaller size and more focused training, it excels in natural language processing tasks and can provide accurate and concise answers to diverse questions.\\n\\n4. **Availability and Access**:\\n   - PaLM: PaLM is not publicly available and is primarily used by Google's internal teams. Access to PaLM is limited and requires special permission.\\n   - Gemini: Gemini is publicly available through Google's Cloud TPU platform. Researchers and developers can access Gemini's API to experiment with the model and build applications.\\n\\n5. **Suitability for Specific Tasks**:\\n   - PaLM: PaLM is suitable for a wide range of tasks, including language generation, code generation, question answering, summarization, and complex reasoning.\\n   - Gemini: Gemini is best suited for natural language processing tasks such as question answering, summarization, dialogue generation, and text classification.\\n\\nOverall, PaLM offers greater model size, more diverse training data, and broader applicability across various tasks. However, Gemini provides efficient performance, excels in natural language processing tasks, and is publicly accessible. Consider these factors carefully to determine which model aligns best with your specific requirements and priorities.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"which llm should I select ,PaLM or Gemini\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d507545-0a56-44bc-b7ce-18ff32fe4c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My knowledge was last updated in September 2021. This means that I do not have access to information about events or developments that have occurred after this date. I recommend checking reputable, up-to-date sources for the most current information.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"when your knowledge based was last updated \").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa46ca-af84-430e-8937-197d8886407e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
